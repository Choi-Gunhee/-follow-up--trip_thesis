{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51e26ba",
   "metadata": {},
   "source": [
    "# load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe4f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7264fdba",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c564de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RESPOND_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EXAMIN_BEGIN_DE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SEX",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "INCOME",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SEOUL",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GYEONGGI",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BUSAN",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CHUNGNAM",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CHUNGBUK",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GYEONGNAM",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GYEONGBUK",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JEONNAM",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JEONBUK",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GANGWAN",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JEJU",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Lodgement",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Food",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Transport",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Shopping",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Activity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Etc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Per_Diem",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Married",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AREA_강원도",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_경기도",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_경상남도",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_경상북도",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_광주광역시",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_대구광역시",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_대전광역시",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_부산광역시",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_서울특별시",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_울산광역시",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_인천광역시",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_전라남도",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_전라북도",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_제주도",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_충청남도(세종시 포함)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AREA_충청북도",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Children_미혼",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Children_신혼기(자녀 없음)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Children_자녀 독립(막내 결혼)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Children_자녀 성인(막내 대학)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Children_자녀 성장(막내 중고생)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Children_자녀 유아&성장(막내 입학전~초등생)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupation_경영/관리/전문직",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupation_기능/숙련/일반작업직",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupation_기타/무직",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupation_대학/대학원생",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupation_사무/기술직",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupation_자영업",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupation_전업주부",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupation_판매/서비스직",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dbscan_cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "kmeans_cluster",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cea7f5f9-588d-411a-9a18-a9268b8e9315",
       "rows": [
        [
         "0",
         "53364346",
         "20240101",
         "0",
         "50",
         "1",
         "3",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "20",
         "10",
         "5",
         "1",
         "1",
         "1",
         "3",
         "2",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "1"
        ],
        [
         "1",
         "53363665",
         "20240101",
         "0",
         "50",
         "0",
         "3",
         "3",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "10",
         "5",
         "5",
         "5",
         "1",
         "1",
         "1",
         "2",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "73",
         "1"
        ],
        [
         "2",
         "53322894",
         "20240101",
         "0",
         "50",
         "1",
         "3",
         "4",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "10",
         "1",
         "1",
         "1",
         "1",
         "1",
         "1",
         "4",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "44",
         "1"
        ],
        [
         "6",
         "53328071",
         "20240101",
         "1",
         "40",
         "1",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "40",
         "10",
         "10",
         "10",
         "10",
         "10",
         "1",
         "4",
         "3",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "34",
         "1"
        ],
        [
         "9",
         "53326024",
         "20240101",
         "0",
         "20",
         "0",
         "3",
         "1",
         "3",
         "1",
         "3",
         "5",
         "1",
         "5",
         "2",
         "3",
         "3",
         "10",
         "10",
         "5",
         "3",
         "1",
         "1",
         "1",
         "4",
         "2",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1",
         "0"
        ],
        [
         "11",
         "53331901",
         "20240101",
         "0",
         "30",
         "1",
         "2",
         "3",
         "3",
         "5",
         "4",
         "2",
         "1",
         "5",
         "5",
         "4",
         "3",
         "40",
         "10",
         "10",
         "5",
         "5",
         "5",
         "1",
         "5",
         "4",
         "0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "41",
         "0"
        ],
        [
         "13",
         "53336250",
         "20240101",
         "1",
         "50",
         "1",
         "2",
         "3",
         "3",
         "3",
         "3",
         "3",
         "2",
         "3",
         "3",
         "3",
         "4",
         "40",
         "5",
         "10",
         "10",
         "1",
         "1",
         "1",
         "5",
         "3",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "16",
         "1"
        ],
        [
         "15",
         "53339544",
         "20240101",
         "1",
         "50",
         "1",
         "3",
         "2",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "40",
         "5",
         "10",
         "5",
         "1",
         "10",
         "1",
         "4",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "15",
         "1"
        ],
        [
         "16",
         "53341363",
         "20240101",
         "0",
         "40",
         "1",
         "4",
         "4",
         "4",
         "2",
         "2",
         "2",
         "2",
         "2",
         "4",
         "4",
         "4",
         "10",
         "1",
         "3",
         "1",
         "1",
         "1",
         "1",
         "4",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "2",
         "1"
        ],
        [
         "17",
         "53341677",
         "20240101",
         "1",
         "30",
         "1",
         "3",
         "5",
         "1",
         "2",
         "2",
         "3",
         "3",
         "5",
         "3",
         "4",
         "5",
         "10",
         "5",
         "1",
         "1",
         "1",
         "3",
         "1",
         "5",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "3",
         "1"
        ],
        [
         "20",
         "53345966",
         "20240101",
         "1",
         "40",
         "1",
         "3",
         "3",
         "4",
         "3",
         "3",
         "3",
         "2",
         "3",
         "3",
         "4",
         "2",
         "10",
         "3",
         "3",
         "3",
         "5",
         "1",
         "1",
         "2",
         "2",
         "0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "4",
         "0"
        ],
        [
         "23",
         "53358527",
         "20240101",
         "0",
         "50",
         "0",
         "4",
         "4",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "2",
         "4",
         "10",
         "1",
         "5",
         "3",
         "1",
         "1",
         "1",
         "3",
         "3",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "5",
         "0"
        ],
        [
         "24",
         "53362103",
         "20240101",
         "0",
         "20",
         "0",
         "3",
         "2",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "2",
         "2",
         "20",
         "7",
         "5",
         "1",
         "1",
         "3",
         "1",
         "2",
         "3",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "6",
         "0"
        ],
        [
         "26",
         "53364226",
         "20240101",
         "1",
         "50",
         "1",
         "3",
         "3",
         "3",
         "4",
         "4",
         "3",
         "3",
         "3",
         "3",
         "4",
         "5",
         "40",
         "1",
         "10",
         "10",
         "1",
         "7",
         "3",
         "5",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "32",
         "1"
        ],
        [
         "27",
         "53367204",
         "20240101",
         "0",
         "50",
         "1",
         "3",
         "3",
         "4",
         "5",
         "4",
         "4",
         "3",
         "3",
         "3",
         "3",
         "5",
         "20",
         "10",
         "10",
         "1",
         "1",
         "1",
         "1",
         "3",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "70",
         "1"
        ],
        [
         "28",
         "53367667",
         "20240101",
         "1",
         "30",
         "1",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "10",
         "3",
         "1",
         "1",
         "1",
         "1",
         "1",
         "2",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "7",
         "1"
        ],
        [
         "29",
         "53374884",
         "20240101",
         "0",
         "20",
         "1",
         "3",
         "4",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "5",
         "10",
         "3",
         "7",
         "1",
         "1",
         "1",
         "1",
         "2",
         "2",
         "0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "4",
         "0"
        ],
        [
         "30",
         "53375471",
         "20240108",
         "0",
         "50",
         "1",
         "2",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "10",
         "1",
         "1",
         "1",
         "1",
         "7",
         "1",
         "2",
         "3",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "8",
         "1"
        ],
        [
         "34",
         "53337862",
         "20240108",
         "0",
         "40",
         "1",
         "4",
         "3",
         "3",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "3",
         "1",
         "10",
         "5",
         "3",
         "1",
         "1",
         "1",
         "1",
         "5",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "9",
         "1"
        ],
        [
         "35",
         "53325803",
         "20240108",
         "0",
         "40",
         "1",
         "3",
         "4",
         "4",
         "1",
         "4",
         "4",
         "1",
         "3",
         "3",
         "2",
         "2",
         "20",
         "5",
         "7",
         "5",
         "1",
         "1",
         "1",
         "5",
         "3",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "9",
         "1"
        ],
        [
         "36",
         "53331311",
         "20240108",
         "0",
         "40",
         "1",
         "4",
         "1",
         "3",
         "1",
         "3",
         "4",
         "3",
         "1",
         "1",
         "3",
         "2",
         "20",
         "10",
         "5",
         "3",
         "1",
         "1",
         "1",
         "3",
         "4",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "2",
         "1"
        ],
        [
         "37",
         "53328601",
         "20240108",
         "0",
         "30",
         "1",
         "3",
         "3",
         "4",
         "5",
         "2",
         "2",
         "2",
         "3",
         "3",
         "5",
         "4",
         "10",
         "1",
         "5",
         "5",
         "1",
         "1",
         "1",
         "2",
         "2",
         "0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "4",
         "0"
        ],
        [
         "39",
         "53376779",
         "20240108",
         "0",
         "20",
         "1",
         "3",
         "3",
         "5",
         "4",
         "3",
         "4",
         "3",
         "4",
         "4",
         "4",
         "5",
         "20",
         "1",
         "10",
         "5",
         "1",
         "5",
         "1",
         "2",
         "4",
         "0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "39",
         "0"
        ],
        [
         "41",
         "53352732",
         "20240108",
         "1",
         "40",
         "1",
         "3",
         "2",
         "3",
         "4",
         "4",
         "3",
         "3",
         "2",
         "2",
         "3",
         "2",
         "20",
         "5",
         "10",
         "5",
         "1",
         "5",
         "1",
         "3",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "10",
         "1"
        ],
        [
         "42",
         "53355377",
         "20240108",
         "1",
         "40",
         "1",
         "4",
         "3",
         "2",
         "4",
         "3",
         "3",
         "2",
         "3",
         "3",
         "4",
         "3",
         "10",
         "5",
         "5",
         "5",
         "1",
         "1",
         "1",
         "2",
         "3",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "11",
         "1"
        ],
        [
         "43",
         "53356648",
         "20240108",
         "1",
         "40",
         "1",
         "4",
         "4",
         "4",
         "2",
         "3",
         "2",
         "3",
         "2",
         "3",
         "4",
         "2",
         "20",
         "3",
         "3",
         "3",
         "1",
         "10",
         "1",
         "3",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "12",
         "1"
        ],
        [
         "44",
         "53328653",
         "20240108",
         "1",
         "40",
         "1",
         "4",
         "4",
         "3",
         "4",
         "2",
         "3",
         "2",
         "2",
         "2",
         "3",
         "3",
         "10",
         "3",
         "5",
         "1",
         "1",
         "1",
         "1",
         "5",
         "2",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1",
         "0"
        ],
        [
         "46",
         "53325071",
         "20240108",
         "1",
         "50",
         "1",
         "1",
         "2",
         "1",
         "1",
         "1",
         "1",
         "1",
         "1",
         "3",
         "4",
         "4",
         "30",
         "5",
         "10",
         "10",
         "5",
         "1",
         "1",
         "3",
         "4",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "1"
        ],
        [
         "47",
         "53326035",
         "20240108",
         "1",
         "50",
         "1",
         "3",
         "4",
         "4",
         "3",
         "3",
         "4",
         "3",
         "3",
         "3",
         "4",
         "3",
         "10",
         "3",
         "1",
         "1",
         "1",
         "1",
         "1",
         "5",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "13",
         "1"
        ],
        [
         "48",
         "53329559",
         "20240108",
         "0",
         "40",
         "0",
         "4",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "3",
         "20",
         "5",
         "5",
         "7",
         "1",
         "1",
         "1",
         "2",
         "2",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "5",
         "0"
        ],
        [
         "50",
         "53332872",
         "20240108",
         "1",
         "50",
         "1",
         "3",
         "2",
         "3",
         "3",
         "3",
         "4",
         "2",
         "3",
         "3",
         "3",
         "2",
         "20",
         "1",
         "10",
         "5",
         "1",
         "5",
         "1",
         "2",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "14",
         "1"
        ],
        [
         "51",
         "53335569",
         "20240108",
         "1",
         "50",
         "1",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "4",
         "3",
         "2",
         "10",
         "1",
         "7",
         "3",
         "1",
         "1",
         "1",
         "4",
         "3",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "33",
         "1"
        ],
        [
         "53",
         "53336599",
         "20240108",
         "0",
         "40",
         "0",
         "2",
         "4",
         "3",
         "2",
         "3",
         "3",
         "3",
         "4",
         "3",
         "3",
         "3",
         "10",
         "3",
         "1",
         "1",
         "1",
         "1",
         "1",
         "4",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "38",
         "1"
        ],
        [
         "55",
         "53343365",
         "20240108",
         "1",
         "50",
         "1",
         "1",
         "1",
         "1",
         "3",
         "1",
         "5",
         "4",
         "5",
         "4",
         "3",
         "3",
         "40",
         "10",
         "10",
         "10",
         "10",
         "10",
         "5",
         "2",
         "5",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "54",
         "1"
        ],
        [
         "63",
         "53351484",
         "20240108",
         "1",
         "50",
         "1",
         "3",
         "3",
         "4",
         "3",
         "3",
         "3",
         "3",
         "4",
         "3",
         "3",
         "3",
         "20",
         "5",
         "10",
         "5",
         "1",
         "1",
         "1",
         "3",
         "4",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "15",
         "1"
        ],
        [
         "64",
         "53353235",
         "20240108",
         "1",
         "50",
         "1",
         "1",
         "1",
         "1",
         "3",
         "4",
         "1",
         "2",
         "3",
         "1",
         "4",
         "4",
         "10",
         "1",
         "5",
         "1",
         "1",
         "1",
         "3",
         "4",
         "3",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "44",
         "1"
        ],
        [
         "68",
         "53373096",
         "20240108",
         "1",
         "50",
         "1",
         "3",
         "3",
         "4",
         "3",
         "3",
         "4",
         "3",
         "2",
         "4",
         "3",
         "1",
         "10",
         "1",
         "10",
         "1",
         "1",
         "1",
         "1",
         "2",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "16",
         "1"
        ],
        [
         "69",
         "53353574",
         "20240115",
         "0",
         "50",
         "1",
         "3",
         "3",
         "4",
         "3",
         "3",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "10",
         "1",
         "5",
         "5",
         "3",
         "1",
         "1",
         "2",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "1"
        ],
        [
         "70",
         "53344174",
         "20240115",
         "0",
         "30",
         "1",
         "4",
         "4",
         "5",
         "3",
         "3",
         "5",
         "4",
         "3",
         "3",
         "4",
         "5",
         "10",
         "1",
         "3",
         "1",
         "1",
         "1",
         "1",
         "3",
         "7",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "5",
         "0"
        ],
        [
         "71",
         "53365191",
         "20240115",
         "0",
         "20",
         "1",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "2",
         "4",
         "3",
         "4",
         "4",
         "10",
         "1",
         "5",
         "5",
         "1",
         "1",
         "1",
         "4",
         "2",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "17",
         "0"
        ],
        [
         "75",
         "405220",
         "20240115",
         "0",
         "50",
         "1",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "30",
         "10",
         "5",
         "10",
         "3",
         "5",
         "1",
         "3",
         "4",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "18",
         "1"
        ],
        [
         "76",
         "53326199",
         "20240115",
         "0",
         "50",
         "1",
         "4",
         "3",
         "3",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "10",
         "1",
         "5",
         "1",
         "3",
         "1",
         "1",
         "4",
         "2",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "35",
         "1"
        ],
        [
         "77",
         "53328468",
         "20240115",
         "1",
         "50",
         "1",
         "2",
         "2",
         "4",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "2",
         "30",
         "5",
         "10",
         "3",
         "1",
         "10",
         "1",
         "4",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "1"
        ],
        [
         "78",
         "53331154",
         "20240115",
         "0",
         "20",
         "1",
         "5",
         "4",
         "5",
         "2",
         "2",
         "3",
         "4",
         "4",
         "4",
         "2",
         "5",
         "10",
         "1",
         "3",
         "1",
         "1",
         "1",
         "1",
         "2",
         "2",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "50",
         "0"
        ],
        [
         "81",
         "53353154",
         "20240115",
         "1",
         "50",
         "1",
         "3",
         "3",
         "5",
         "2",
         "3",
         "3",
         "2",
         "4",
         "4",
         "4",
         "2",
         "10",
         "7",
         "3",
         "1",
         "1",
         "3",
         "1",
         "3",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "12",
         "1"
        ],
        [
         "83",
         "53358733",
         "20240115",
         "1",
         "40",
         "0",
         "4",
         "3",
         "3",
         "2",
         "4",
         "3",
         "4",
         "3",
         "2",
         "2",
         "2",
         "20",
         "5",
         "10",
         "3",
         "1",
         "1",
         "1",
         "1",
         "2",
         "0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "19",
         "0"
        ],
        [
         "84",
         "53359547",
         "20240115",
         "1",
         "30",
         "1",
         "3",
         "3",
         "2",
         "3",
         "3",
         "4",
         "3",
         "3",
         "3",
         "4",
         "3",
         "10",
         "7",
         "5",
         "1",
         "1",
         "1",
         "1",
         "2",
         "2",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "20",
         "1"
        ],
        [
         "86",
         "53364492",
         "20240115",
         "1",
         "40",
         "1",
         "2",
         "2",
         "4",
         "2",
         "1",
         "3",
         "4",
         "2",
         "2",
         "1",
         "3",
         "10",
         "3",
         "1",
         "1",
         "1",
         "1",
         "1",
         "5",
         "4",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "21",
         "1"
        ],
        [
         "87",
         "53365448",
         "20240115",
         "0",
         "40",
         "1",
         "3",
         "3",
         "4",
         "2",
         "3",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "10",
         "1",
         "5",
         "1",
         "1",
         "1",
         "1",
         "3",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "2",
         "1"
        ],
        [
         "88",
         "53368117",
         "20240115",
         "0",
         "50",
         "1",
         "2",
         "3",
         "4",
         "3",
         "3",
         "2",
         "2",
         "2",
         "2",
         "3",
         "3",
         "40",
         "10",
         "10",
         "5",
         "1",
         "1",
         "1",
         "2",
         "2",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "22",
         "1"
        ]
       ],
       "shape": {
        "columns": 58,
        "rows": 1006
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESPOND_ID</th>\n",
       "      <th>EXAMIN_BEGIN_DE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>SEOUL</th>\n",
       "      <th>GYEONGGI</th>\n",
       "      <th>BUSAN</th>\n",
       "      <th>CHUNGNAM</th>\n",
       "      <th>CHUNGBUK</th>\n",
       "      <th>...</th>\n",
       "      <th>Occupation_경영/관리/전문직</th>\n",
       "      <th>Occupation_기능/숙련/일반작업직</th>\n",
       "      <th>Occupation_기타/무직</th>\n",
       "      <th>Occupation_대학/대학원생</th>\n",
       "      <th>Occupation_사무/기술직</th>\n",
       "      <th>Occupation_자영업</th>\n",
       "      <th>Occupation_전업주부</th>\n",
       "      <th>Occupation_판매/서비스직</th>\n",
       "      <th>dbscan_cluster</th>\n",
       "      <th>kmeans_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53364346</td>\n",
       "      <td>20240101</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53363665</td>\n",
       "      <td>20240101</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53322894</td>\n",
       "      <td>20240101</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53328071</td>\n",
       "      <td>20240101</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53326024</td>\n",
       "      <td>20240101</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>53350730</td>\n",
       "      <td>20241230</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>53364632</td>\n",
       "      <td>20241230</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>53367863</td>\n",
       "      <td>20241230</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>53369696</td>\n",
       "      <td>20241230</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>53370112</td>\n",
       "      <td>20241230</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RESPOND_ID  EXAMIN_BEGIN_DE  SEX  AGE  INCOME  SEOUL  GYEONGGI  BUSAN  \\\n",
       "0       53364346         20240101    0   50       1      3         4      3   \n",
       "1       53363665         20240101    0   50       0      3         3      4   \n",
       "2       53322894         20240101    0   50       1      3         4      4   \n",
       "6       53328071         20240101    1   40       1      3         3      3   \n",
       "9       53326024         20240101    0   20       0      3         1      3   \n",
       "...          ...              ...  ...  ...     ...    ...       ...    ...   \n",
       "1562    53350730         20241230    0   50       0      1         4      3   \n",
       "1566    53364632         20241230    1   50       1      3         4      4   \n",
       "1570    53367863         20241230    0   40       1      1         2      4   \n",
       "1571    53369696         20241230    1   50       1      3         4      1   \n",
       "1572    53370112         20241230    0   40       1      3         3      4   \n",
       "\n",
       "      CHUNGNAM  CHUNGBUK  ...  Occupation_경영/관리/전문직  Occupation_기능/숙련/일반작업직  \\\n",
       "0            3         3  ...                   0.0                     0.0   \n",
       "1            3         3  ...                   0.0                     0.0   \n",
       "2            3         3  ...                   0.0                     0.0   \n",
       "6            3         3  ...                   0.0                     0.0   \n",
       "9            1         3  ...                   0.0                     0.0   \n",
       "...        ...       ...  ...                   ...                     ...   \n",
       "1562         1         1  ...                   0.0                     0.0   \n",
       "1566         1         2  ...                   0.0                     0.0   \n",
       "1570         2         3  ...                   0.0                     0.0   \n",
       "1571         1         2  ...                   0.0                     0.0   \n",
       "1572         3         3  ...                   0.0                     0.0   \n",
       "\n",
       "      Occupation_기타/무직  Occupation_대학/대학원생  Occupation_사무/기술직  Occupation_자영업  \\\n",
       "0                  0.0                 0.0                1.0             0.0   \n",
       "1                  0.0                 0.0                0.0             0.0   \n",
       "2                  0.0                 0.0                0.0             1.0   \n",
       "6                  0.0                 0.0                1.0             0.0   \n",
       "9                  0.0                 0.0                1.0             0.0   \n",
       "...                ...                 ...                ...             ...   \n",
       "1562               0.0                 0.0                0.0             0.0   \n",
       "1566               0.0                 0.0                1.0             0.0   \n",
       "1570               0.0                 0.0                1.0             0.0   \n",
       "1571               0.0                 0.0                1.0             0.0   \n",
       "1572               0.0                 0.0                0.0             0.0   \n",
       "\n",
       "      Occupation_전업주부  Occupation_판매/서비스직  dbscan_cluster  kmeans_cluster  \n",
       "0                 0.0                 0.0               0               1  \n",
       "1                 0.0                 1.0              73               1  \n",
       "2                 0.0                 0.0              44               1  \n",
       "6                 0.0                 0.0              34               1  \n",
       "9                 0.0                 0.0               1               0  \n",
       "...               ...                 ...             ...             ...  \n",
       "1562              1.0                 0.0              35               1  \n",
       "1566              0.0                 0.0              11               1  \n",
       "1570              0.0                 0.0               2               1  \n",
       "1571              0.0                 0.0               0               1  \n",
       "1572              0.0                 1.0              50               0  \n",
       "\n",
       "[1006 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터프레임 로드\n",
    "cluster_df = pd.read_csv('preprocessed data/cluster_df.csv', index_col=0)\n",
    "cluster_df = cluster_df[cluster_df['dbscan_cluster']!=-1]\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fad38",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb330c",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier prediction for dbscan cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cd07cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 603 samples\n",
      "validation set size: 201 samples\n",
      "test set size: 202 samples\n",
      "Validation set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      0.67      0.80         9\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.75      0.75      0.75         4\n",
      "           9       0.80      1.00      0.89         4\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00         7\n",
      "          13       0.40      0.67      0.50         3\n",
      "          14       0.67      1.00      0.80         2\n",
      "          15       0.50      1.00      0.67         1\n",
      "          16       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      0.80      0.89         5\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      0.75      0.86         4\n",
      "          23       1.00      0.67      0.80         3\n",
      "          24       0.50      0.33      0.40         3\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      0.50      0.67         2\n",
      "          28       1.00      0.86      0.92         7\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       0.50      1.00      0.67         1\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       0.80      1.00      0.89         4\n",
      "          35       0.92      0.92      0.92        13\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.75      1.00      0.86         3\n",
      "          38       1.00      1.00      1.00         1\n",
      "          39       1.00      0.50      0.67         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      1.00      1.00         1\n",
      "          45       0.50      0.50      0.50         2\n",
      "          46       1.00      1.00      1.00         1\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         3\n",
      "          49       1.00      0.75      0.86         4\n",
      "          50       1.00      1.00      1.00         3\n",
      "          51       0.50      1.00      0.67         1\n",
      "          53       0.67      1.00      0.80         2\n",
      "          54       0.67      1.00      0.80         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       1.00      1.00      1.00         1\n",
      "          62       1.00      1.00      1.00         1\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         1\n",
      "          66       1.00      1.00      1.00         1\n",
      "          67       1.00      0.50      0.67         2\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       0.33      1.00      0.50         1\n",
      "          71       0.50      1.00      0.67         1\n",
      "          72       1.00      1.00      1.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.89       201\n",
      "   macro avg       0.84      0.87      0.84       201\n",
      "weighted avg       0.90      0.89      0.88       201\n",
      "\n",
      "Test set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       1.00      0.88      0.93         8\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         8\n",
      "           9       1.00      0.25      0.40         4\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00        11\n",
      "          12       1.00      1.00      1.00         9\n",
      "          13       1.00      0.50      0.67         4\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         1\n",
      "          16       1.00      1.00      1.00         9\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       0.67      1.00      0.80         2\n",
      "          22       1.00      0.50      0.67         2\n",
      "          23       1.00      1.00      1.00         1\n",
      "          24       0.33      0.50      0.40         2\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       0.86      1.00      0.92         6\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         5\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       1.00      1.00      1.00         6\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       1.00      1.00      1.00         1\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         4\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       0.50      0.67      0.57         3\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       1.00      1.00      1.00         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       0.25      1.00      0.40         1\n",
      "          46       0.33      1.00      0.50         1\n",
      "          47       1.00      1.00      1.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       1.00      0.75      0.86         4\n",
      "          51       1.00      1.00      1.00         3\n",
      "          52       0.50      0.33      0.40         3\n",
      "          54       0.88      1.00      0.93         7\n",
      "          56       0.50      1.00      0.67         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       0.50      1.00      0.67         1\n",
      "          60       0.67      1.00      0.80         2\n",
      "          61       1.00      1.00      1.00         1\n",
      "          62       1.00      1.00      1.00         3\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      0.75      0.86         4\n",
      "          66       1.00      1.00      1.00         1\n",
      "          68       0.67      1.00      0.80         2\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       0.50      1.00      0.67         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.90       202\n",
      "   macro avg       0.84      0.85      0.83       202\n",
      "weighted avg       0.93      0.90      0.90       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) feature / target 분리\n",
    "X = cluster_df.iloc[:, 2:-2].to_numpy()\n",
    "y = cluster_df.iloc[:,-2:-1].values.reshape(-1)\n",
    "# 2) train + temp (validation + test) 분리\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# 3) validation / test 분리 (temp 40% -> 20% val + 20% test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"train set size: {X_train.shape[0]} samples\")\n",
    "print(f\"validation set size: {X_val.shape[0]} samples\")\n",
    "print(f\"test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# 4) 모델 학습 및 검증 예시\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터 예측 및 평가\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation set performance:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test set performance:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe56e1f",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier prediction for kmeans cluster(다양한 페르소나의 군집을 예측하는 것이 목표이기에 의미를 두지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9119683d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 603 samples\n",
      "validation set size: 201 samples\n",
      "test set size: 202 samples\n",
      "Validation set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        52\n",
      "           1       0.99      1.00      1.00       149\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Test set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        63\n",
      "           1       0.99      1.00      1.00       139\n",
      "\n",
      "    accuracy                           1.00       202\n",
      "   macro avg       1.00      0.99      0.99       202\n",
      "weighted avg       1.00      1.00      1.00       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) feature / target 분리\n",
    "X = cluster_df.iloc[:, 2:-2].to_numpy()\n",
    "y = cluster_df.iloc[:,-1:].values.reshape(-1)\n",
    "# 2) train + temp (validation + test) 분리\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# 3) validation / test 분리 (temp 40% -> 20% val + 20% test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"train set size: {X_train.shape[0]} samples\")\n",
    "print(f\"validation set size: {X_val.shape[0]} samples\")\n",
    "print(f\"test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# 4) 모델 학습 및 검증 예시\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터 예측 및 평가\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation set performance:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test set performance:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9812e37",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier prediction for kmeans cluster & dbscan cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01343e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation Class 0] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 69\n",
      "[Validation Class 1] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 144\n",
      "[Validation Class 2] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 3] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Validation Class 4] Precision: 0.5000, Recall: 1.0000, F1: 0.6667, Support: 1\n",
      "[Validation Class 5] Precision: 1.0000, Recall: 0.8333, F1: 0.9091, Support: 6\n",
      "[Validation Class 6] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Validation Class 7] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 8] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 9] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 10\n",
      "[Validation Class 10] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 11] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 12] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 13] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 8\n",
      "[Validation Class 14] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 15] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 16] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Validation Class 17] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Validation Class 18] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 19] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 20] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 21] Precision: 0.8571, Recall: 1.0000, F1: 0.9231, Support: 6\n",
      "[Validation Class 22] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 23] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 24] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 7\n",
      "[Validation Class 25] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 26] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 27] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 28] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Validation Class 29] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 10\n",
      "[Validation Class 30] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 31] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 32] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 33] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 34] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 35] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 36] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 37] Precision: 1.0000, Recall: 0.5000, F1: 0.6667, Support: 2\n",
      "[Validation Class 38] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 39] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 40] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 41] Precision: 1.0000, Recall: 0.6667, F1: 0.8000, Support: 3\n",
      "[Validation Class 42] Precision: 0.6667, Recall: 1.0000, F1: 0.8000, Support: 2\n",
      "[Validation Class 43] Precision: 0.5000, Recall: 1.0000, F1: 0.6667, Support: 1\n",
      "[Validation Class 44] Precision: 0.5000, Recall: 1.0000, F1: 0.6667, Support: 1\n",
      "[Validation Class 45] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 7\n",
      "[Validation Class 46] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 47] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 48] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 49] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 50] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 51] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 52] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 53] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 54] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 55] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 56] Precision: 0.6667, Recall: 0.6667, F1: 0.6667, Support: 3\n",
      "[Validation Class 57] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 58] Precision: 0.6667, Recall: 1.0000, F1: 0.8000, Support: 2\n",
      "[Validation Class 59] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 60] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 61] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 62] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Macro]    Precision: 0.9263, Recall: 0.9471, F1: 0.9296\n",
      "[Validation Weighted] Precision: 0.9809, Recall: 0.9826, F1: 0.9799\n",
      "[Test Class 0] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 46\n",
      "[Test Class 1] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 165\n",
      "[Test Class 2] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 3] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Test Class 4] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Test Class 5] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 6] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 7] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Test Class 8] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Test Class 9] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Test Class 10] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 11] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 8\n",
      "[Test Class 12] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 14\n",
      "[Test Class 13] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 14] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 15] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 16] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 11\n",
      "[Test Class 17] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 18] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 19] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Test Class 20] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 21] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 22] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Test Class 23] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Test Class 24] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 7\n",
      "[Test Class 25] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 26] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 7\n",
      "[Test Class 27] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 28] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 29] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Test Class 30] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 31] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 32] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 33] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 11\n",
      "[Test Class 34] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 35] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 36] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 37] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 38] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 39] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Test Class 40] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 41] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 42] Precision: 1.0000, Recall: 0.5000, F1: 0.6667, Support: 4\n",
      "[Test Class 43] Precision: 0.5000, Recall: 1.0000, F1: 0.6667, Support: 1\n",
      "[Test Class 44] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 45] Precision: 0.6667, Recall: 1.0000, F1: 0.8000, Support: 2\n",
      "[Test Class 46] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 47] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 48] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 49] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 50] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 51] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 52] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 53] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 0\n",
      "[Test Class 54] Precision: 0.5000, Recall: 1.0000, F1: 0.6667, Support: 1\n",
      "[Test Class 55] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 56] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 57] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 58] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 0\n",
      "[Test Class 59] Precision: 0.3333, Recall: 1.0000, F1: 0.5000, Support: 1\n",
      "[Test Class 60] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 61] Precision: 1.0000, Recall: 0.5000, F1: 0.6667, Support: 2\n",
      "[Test Class 62] Precision: 0.5000, Recall: 1.0000, F1: 0.6667, Support: 1\n",
      "[Test Class 63] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Test Macro]    Precision: 0.8828, Recall: 0.9062, F1: 0.8849\n",
      "[Test Weighted] Precision: 0.9781, Recall: 0.9777, F1: 0.9755\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "# 1) feature / target 분리 (타겟 여러 컬럼)\n",
    "X = cluster_df.iloc[:, 2:]\n",
    "y = cluster_df.iloc[:, -2:]  # 다중 라벨 (2개)\n",
    "\n",
    "# 2) train + temp 분리\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# 3) val / test 분리\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 4) 모델 학습\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) 검증 데이터 예측\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# 6) 평가 함수 정의\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def print_scores(y_true, y_pred, set_name=\"\"):\n",
    "    # 각 클래스별 score와 support\n",
    "    precisions, recalls, f1s, supports = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average=None, zero_division=0\n",
    "    )\n",
    "    for i, (p, r, f, s) in enumerate(zip(precisions, recalls, f1s, supports)):\n",
    "        print(f\"[{set_name} Class {i}] Precision: {p:.4f}, Recall: {r:.4f}, F1: {f:.4f}, Support: {s}\")\n",
    "\n",
    "    # macro, weighted score\n",
    "    p_macro, r_macro, f_macro, _ = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average='macro', zero_division=0\n",
    "    )\n",
    "    p_weighted, r_weighted, f_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average='weighted', zero_division=0\n",
    "    )\n",
    "    print(f\"[{set_name} Macro]    Precision: {p_macro:.4f}, Recall: {r_macro:.4f}, F1: {f_macro:.4f}\")\n",
    "    print(f\"[{set_name} Weighted] Precision: {p_weighted:.4f}, Recall: {r_weighted:.4f}, F1: {f_weighted:.4f}\")\n",
    "\n",
    "# 7) 검증/테스트 세트 평가지표 출력\n",
    "print_scores(y_val.values, y_val_pred, set_name=\"Validation\")\n",
    "print_scores(y_test.values, y_test_pred, set_name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b89f4",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e65a1",
   "metadata": {},
   "source": [
    "### Random Forest for dbscan cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b86b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 603 samples\n",
      "validation set size: 201 samples\n",
      "test set size: 202 samples\n",
      "Validation set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       0.86      1.00      0.92         6\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      0.75      0.86         4\n",
      "           9       1.00      1.00      1.00         4\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       0.88      1.00      0.93         7\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         1\n",
      "          16       0.83      1.00      0.91         5\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       1.00      1.00      1.00         5\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         3\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      0.86      0.92         7\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       0.80      1.00      0.89         4\n",
      "          35       0.93      1.00      0.96        13\n",
      "          36       1.00      0.50      0.67         2\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       1.00      1.00      1.00         1\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      1.00      1.00         1\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         1\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         3\n",
      "          49       1.00      0.75      0.86         4\n",
      "          50       1.00      1.00      1.00         3\n",
      "          51       1.00      1.00      1.00         1\n",
      "          53       0.67      1.00      0.80         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       1.00      1.00      1.00         1\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         1\n",
      "          66       1.00      1.00      1.00         1\n",
      "          67       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       1.00      1.00      1.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.97       201\n",
      "   macro avg       0.97      0.96      0.96       201\n",
      "weighted avg       0.97      0.97      0.96       201\n",
      "\n",
      "Test set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.75      1.00      0.86         6\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      0.88      0.93         8\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      1.00      1.00         8\n",
      "           9       1.00      1.00      1.00         4\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00        11\n",
      "          12       1.00      1.00      1.00         9\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         1\n",
      "          16       1.00      1.00      1.00         9\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       0.50      1.00      0.67         1\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.80      1.00      0.89         4\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         1\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       0.75      1.00      0.86         6\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         5\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       1.00      1.00      1.00         6\n",
      "          33       1.00      1.00      1.00         1\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         4\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      1.00      1.00         3\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       1.00      1.00      1.00         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      1.00      1.00         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       1.00      1.00      1.00         1\n",
      "          47       1.00      1.00      1.00         1\n",
      "          50       1.00      1.00      1.00         4\n",
      "          51       1.00      1.00      1.00         3\n",
      "          52       1.00      1.00      1.00         3\n",
      "          54       0.88      1.00      0.93         7\n",
      "          56       0.67      1.00      0.80         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         1\n",
      "          62       1.00      1.00      1.00         3\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         4\n",
      "          66       1.00      1.00      1.00         1\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96       202\n",
      "   macro avg       0.91      0.93      0.92       202\n",
      "weighted avg       0.94      0.96      0.94       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) feature / target 분리\n",
    "X = cluster_df.iloc[:, 2:-2].to_numpy()\n",
    "y = cluster_df.iloc[:, -2:-1].values.reshape(-1)\n",
    "\n",
    "# 2) train + temp (validation + test) 분리\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) validation / test 분리 (temp 40% -> 20% val + 20% test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"train set size: {X_train.shape[0]} samples\")\n",
    "print(f\"validation set size: {X_val.shape[0]} samples\")\n",
    "print(f\"test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# 4) 모델 학습 및 검증 예시 (Random Forest)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터 예측 및 평가\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation set performance:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test set performance:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9e3b6",
   "metadata": {},
   "source": [
    "### RandomForest for kmeans cluster & dbscan cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation Class 0] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 69\n",
      "[Validation Class 1] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 144\n",
      "[Validation Class 2] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 3] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Validation Class 4] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 5] Precision: 1.0000, Recall: 0.8333, F1: 0.9091, Support: 6\n",
      "[Validation Class 6] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Validation Class 7] Precision: 0.7500, Recall: 1.0000, F1: 0.8571, Support: 3\n",
      "[Validation Class 8] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 9] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 10\n",
      "[Validation Class 10] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 11] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 12] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 13] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 8\n",
      "[Validation Class 14] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 15] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 16] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Validation Class 17] Precision: 0.6667, Recall: 1.0000, F1: 0.8000, Support: 4\n",
      "[Validation Class 18] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 19] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 20] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 21] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Validation Class 22] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 23] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 24] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 7\n",
      "[Validation Class 25] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 26] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 27] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 28] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Validation Class 29] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 10\n",
      "[Validation Class 30] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 31] Precision: 0.6667, Recall: 1.0000, F1: 0.8000, Support: 2\n",
      "[Validation Class 32] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 33] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Validation Class 34] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 35] Precision: 0.5000, Recall: 0.3333, F1: 0.4000, Support: 3\n",
      "[Validation Class 36] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 37] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 38] Precision: 0.6667, Recall: 1.0000, F1: 0.8000, Support: 2\n",
      "[Validation Class 39] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 40] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 41] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 42] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 43] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 44] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 45] Precision: 0.8750, Recall: 1.0000, F1: 0.9333, Support: 7\n",
      "[Validation Class 46] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 47] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 48] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 49] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 50] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 51] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 52] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 53] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 54] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Validation Class 55] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 56] Precision: 1.0000, Recall: 0.6667, F1: 0.8000, Support: 3\n",
      "[Validation Class 57] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 58] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 59] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Validation Class 60] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Validation Class 61] Precision: 1.0000, Recall: 0.5000, F1: 0.6667, Support: 2\n",
      "[Validation Class 62] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Macro]    Precision: 0.9226, Recall: 0.9259, F1: 0.9201\n",
      "[Validation Weighted] Precision: 0.9756, Recall: 0.9776, F1: 0.9749\n",
      "[Test Class 0] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 46\n",
      "[Test Class 1] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 165\n",
      "[Test Class 2] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 3] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Test Class 4] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Test Class 5] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 6] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 7] Precision: 0.8000, Recall: 1.0000, F1: 0.8889, Support: 4\n",
      "[Test Class 8] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Test Class 9] Precision: 0.8333, Recall: 1.0000, F1: 0.9091, Support: 5\n",
      "[Test Class 10] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 11] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 8\n",
      "[Test Class 12] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 14\n",
      "[Test Class 13] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 14] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 15] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 16] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 11\n",
      "[Test Class 17] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 18] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 19] Precision: 0.5714, Recall: 1.0000, F1: 0.7273, Support: 4\n",
      "[Test Class 20] Precision: 0.7500, Recall: 1.0000, F1: 0.8571, Support: 3\n",
      "[Test Class 21] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 22] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 5\n",
      "[Test Class 23] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 4\n",
      "[Test Class 24] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 7\n",
      "[Test Class 25] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 26] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 7\n",
      "[Test Class 27] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 28] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 29] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Test Class 30] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 31] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 32] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 33] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 11\n",
      "[Test Class 34] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 0\n",
      "[Test Class 35] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 36] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 37] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 38] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 39] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 40] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 6\n",
      "[Test Class 41] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 42] Precision: 0.5000, Recall: 1.0000, F1: 0.6667, Support: 1\n",
      "[Test Class 43] Precision: 1.0000, Recall: 0.2500, F1: 0.4000, Support: 4\n",
      "[Test Class 44] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 45] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 46] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 47] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 48] Precision: 0.5000, Recall: 1.0000, F1: 0.6667, Support: 1\n",
      "[Test Class 49] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 50] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 51] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 52] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 53] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 54] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 55] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 2\n",
      "[Test Class 56] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 3\n",
      "[Test Class 57] Precision: 1.0000, Recall: 0.6667, F1: 0.8000, Support: 3\n",
      "[Test Class 58] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 59] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 60] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 61] Precision: 1.0000, Recall: 1.0000, F1: 1.0000, Support: 1\n",
      "[Test Class 62] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Test Macro]    Precision: 0.9040, Recall: 0.9193, F1: 0.9034\n",
      "[Test Weighted] Precision: 0.9701, Recall: 0.9728, F1: 0.9676\n"
     ]
    }
   ],
   "source": [
    "# 1) feature / target 분리 (타겟 여러 컬럼)\n",
    "X = cluster_df.iloc[:, 2:]\n",
    "y = cluster_df.iloc[:, -2:]  # 다중 라벨 (2개)\n",
    "\n",
    "# 2) train + temp 분리\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# 3) val / test 분리\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# 4) 모델 학습 (Random Forest로 변경)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) 검증 데이터 예측\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# 6) 평가 함수 정의\n",
    "def print_scores(y_true, y_pred, set_name=\"\"):\n",
    "    # 각 클래스별 score와 support\n",
    "    precisions, recalls, f1s, supports = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average=None, zero_division=0\n",
    "    )\n",
    "    for i, (p, r, f, s) in enumerate(zip(precisions, recalls, f1s, supports)):\n",
    "        print(f\"[{set_name} Class {i}] Precision: {p:.4f}, Recall: {r:.4f}, F1: {f:.4f}, Support: {s}\")\n",
    "\n",
    "    # macro, weighted score\n",
    "    p_macro, r_macro, f_macro, _ = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average='macro', zero_division=0\n",
    "    )\n",
    "    p_weighted, r_weighted, f_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average='weighted', zero_division=0\n",
    "    )\n",
    "    print(f\"[{set_name} Macro]    Precision: {p_macro:.4f}, Recall: {r_macro:.4f}, F1: {f_macro:.4f}\")\n",
    "    print(f\"[{set_name} Weighted] Precision: {p_weighted:.4f}, Recall: {r_weighted:.4f}, F1: {f_weighted:.4f}\")\n",
    "\n",
    "# 7) 검증/테스트 세트 평가지표 출력\n",
    "print_scores(y_val.values, y_val_pred, set_name=\"Validation\")\n",
    "print_scores(y_test.values, y_test_pred, set_name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa37c9",
   "metadata": {},
   "source": [
    "# Neural Networks, MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e67553",
   "metadata": {},
   "source": [
    "### MLP for dbscan cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d69ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:27<00:00, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       0.86      1.00      0.92         6\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       0.75      0.75      0.75         4\n",
      "           9       0.80      1.00      0.89         4\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00         7\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         1\n",
      "          16       0.83      1.00      0.91         5\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.50      1.00      0.67         1\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       1.00      0.60      0.75         5\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       0.40      0.50      0.44         4\n",
      "          23       1.00      0.67      0.80         3\n",
      "          24       1.00      1.00      1.00         3\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      0.50      0.67         2\n",
      "          28       1.00      0.71      0.83         7\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       0.67      1.00      0.80         4\n",
      "          35       0.91      0.77      0.83        13\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      0.67      0.80         3\n",
      "          38       1.00      1.00      1.00         1\n",
      "          39       1.00      0.50      0.67         2\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      1.00      1.00         1\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         1\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      0.67      0.80         3\n",
      "          49       0.75      0.75      0.75         4\n",
      "          50       1.00      1.00      1.00         3\n",
      "          51       0.00      0.00      0.00         1\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       0.50      1.00      0.67         2\n",
      "          55       1.00      0.50      0.67         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       1.00      1.00      1.00         1\n",
      "          62       1.00      1.00      1.00         1\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         1\n",
      "          66       1.00      1.00      1.00         1\n",
      "          67       1.00      0.50      0.67         2\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.50      1.00      0.67         1\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       0.33      1.00      0.50         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.88       201\n",
      "   macro avg       0.86      0.85      0.84       201\n",
      "weighted avg       0.92      0.88      0.88       201\n",
      "\n",
      "Test set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.86      1.00      0.92         6\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      0.88      0.93         8\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       0.89      1.00      0.94         8\n",
      "           9       1.00      0.75      0.86         4\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00        11\n",
      "          12       1.00      1.00      1.00         9\n",
      "          13       0.80      1.00      0.89         4\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         1\n",
      "          16       0.90      1.00      0.95         9\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       0.83      1.00      0.91         5\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       1.00      0.50      0.67         2\n",
      "          28       1.00      1.00      1.00         5\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       1.00      1.00      1.00         6\n",
      "          33       1.00      1.00      1.00         1\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         4\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       0.67      1.00      0.80         2\n",
      "          39       1.00      0.67      0.80         3\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.75      1.00      0.86         3\n",
      "          43       0.75      1.00      0.86         3\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       0.50      1.00      0.67         1\n",
      "          47       1.00      1.00      1.00         1\n",
      "          50       1.00      1.00      1.00         4\n",
      "          51       1.00      1.00      1.00         3\n",
      "          52       0.75      1.00      0.86         3\n",
      "          54       0.86      0.86      0.86         7\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       0.33      1.00      0.50         1\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         1\n",
      "          62       1.00      1.00      1.00         3\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      0.50      0.67         4\n",
      "          66       0.33      1.00      0.50         1\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       0.50      1.00      0.67         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.92       202\n",
      "   macro avg       0.87      0.89      0.86       202\n",
      "weighted avg       0.93      0.92      0.91       202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 분리 (기존과 동일)\n",
    "X = cluster_df.iloc[:, 2:-2].to_numpy()\n",
    "y = cluster_df.iloc[:, -2:-1].values.reshape(-1)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# 텐서 변환\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "# DataLoader 준비\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# MLP 모델 정의\n",
    "n_inputs = X_train.shape[1]\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = MLP(n_inputs, n_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 루프\n",
    "n_epochs = 1000\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 검증 및 테스트 평가 함수\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            outputs = model(xb)\n",
    "            pred = outputs.argmax(dim=1).cpu().numpy()\n",
    "            true = yb.cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "    preds = np.concatenate(preds)\n",
    "    trues = np.concatenate(trues)\n",
    "    return trues, preds\n",
    "\n",
    "# 성능 출력\n",
    "y_val_true, y_val_pred = evaluate(model, val_loader)\n",
    "print(\"Validation set performance:\")\n",
    "print(classification_report(y_val_true, y_val_pred, zero_division=0))\n",
    "\n",
    "y_test_true, y_test_pred = evaluate(model, test_loader)\n",
    "print(\"Test set performance:\")\n",
    "print(classification_report(y_test_true, y_test_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc39eb",
   "metadata": {},
   "source": [
    "### mlp for kmeans cluster & dbscan cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ea8a624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [13:39<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation Class 0] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 69\n",
      "[Validation Class 1] Precision: 0.3582, Recall: 1.0000, F1: 0.5275, Support: 144\n",
      "[Validation Class 2] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 3] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 6\n",
      "[Validation Class 4] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 5] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 6\n",
      "[Validation Class 6] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 6\n",
      "[Validation Class 7] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 8] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 9] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 10\n",
      "[Validation Class 10] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 5\n",
      "[Validation Class 11] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 5\n",
      "[Validation Class 12] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 13] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 8\n",
      "[Validation Class 14] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 15] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 16] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Validation Class 17] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Validation Class 18] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 19] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 20] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 21] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 6\n",
      "[Validation Class 22] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 5\n",
      "[Validation Class 23] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 24] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 7\n",
      "[Validation Class 25] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 26] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 27] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 28] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Validation Class 29] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 10\n",
      "[Validation Class 30] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 31] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 32] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 5\n",
      "[Validation Class 33] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 5\n",
      "[Validation Class 34] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 35] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 36] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 37] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 38] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 39] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 40] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 41] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 42] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 43] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 44] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 45] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 7\n",
      "[Validation Class 46] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 47] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 48] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 49] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 50] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 51] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 52] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 53] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 54] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 55] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 56] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Validation Class 57] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 58] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 59] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 60] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Validation Class 61] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Class 62] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Validation Macro]    Precision: 0.0057, Recall: 0.0159, F1: 0.0084\n",
      "[Validation Weighted] Precision: 0.1283, Recall: 0.3582, F1: 0.1889\n",
      "[Test Class 0] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 46\n",
      "[Test Class 1] Precision: 0.4084, Recall: 1.0000, F1: 0.5800, Support: 165\n",
      "[Test Class 2] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 3] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Test Class 4] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 6\n",
      "[Test Class 5] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 6] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 7] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Test Class 8] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 6\n",
      "[Test Class 9] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 5\n",
      "[Test Class 10] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 11] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 8\n",
      "[Test Class 12] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 14\n",
      "[Test Class 13] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 14] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 15] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 16] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 11\n",
      "[Test Class 17] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 18] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 19] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Test Class 20] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 21] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 22] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 5\n",
      "[Test Class 23] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Test Class 24] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 7\n",
      "[Test Class 25] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 26] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 7\n",
      "[Test Class 27] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 28] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 29] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 6\n",
      "[Test Class 30] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 31] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 32] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 33] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 11\n",
      "[Test Class 34] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 35] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 36] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 37] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 38] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 39] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 6\n",
      "[Test Class 40] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 41] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 42] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Test Class 43] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 44] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 45] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 46] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 47] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 48] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 49] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 50] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 51] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 52] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 53] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 54] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 55] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 56] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 3\n",
      "[Test Class 57] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 58] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 59] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 2\n",
      "[Test Class 60] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 1\n",
      "[Test Class 61] Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Support: 4\n",
      "[Test Macro]    Precision: 0.0066, Recall: 0.0161, F1: 0.0094\n",
      "[Test Weighted] Precision: 0.1668, Recall: 0.4084, F1: 0.2369\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# 1) feature / target 분리 (타겟 여러 컬럼)\n",
    "X = cluster_df.iloc[:, 2:].to_numpy(dtype=np.float32)\n",
    "y = cluster_df.iloc[:, -2:].to_numpy(dtype=np.float32)  # 다중 라벨 (2개 이상 assumed)\n",
    "\n",
    "# 2) train + temp 분리\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# 3) val / test 분리\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# 텐서 변환\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# DataLoader 준비\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=32)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32)\n",
    "\n",
    "# 4) 모델 정의 (Multi-label에 맞는 출력층)\n",
    "n_inputs = X_train.shape[1]\n",
    "n_targets = y_train.shape[1]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)  # BCEWithLogitsLoss는 sigmoid 미적용 출력 기대\n",
    "\n",
    "model = MLP(n_inputs, n_targets).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 멀티라벨 이진 분류용\n",
    "\n",
    "# 5) 학습 루프\n",
    "n_epochs = 10000\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 6) 평가 함수\n",
    "def get_preds_targets(model, loader):\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    trues_list = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            outputs = model(xb)\n",
    "            probs = torch.sigmoid(outputs)     # 확률로 변환\n",
    "            preds = (probs > 0.5).cpu().numpy().astype(int)\n",
    "            preds_list.append(preds)\n",
    "            trues_list.append(yb.cpu().numpy())\n",
    "    preds = np.concatenate(preds_list, axis=0)\n",
    "    trues = np.concatenate(trues_list, axis=0)\n",
    "    return trues, preds\n",
    "\n",
    "# 7) 성능 평가 (기존 print_scores 함수 사용)\n",
    "def print_scores(y_true, y_pred, set_name=\"\"):\n",
    "    # flatten해서 평가 (멀티라벨 평균)\n",
    "    precisions, recalls, f1s, supports = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average=None, zero_division=0\n",
    "    )\n",
    "    for i, (p, r, f, s) in enumerate(zip(precisions, recalls, f1s, supports)):\n",
    "        print(f\"[{set_name} Class {i}] Precision: {p:.4f}, Recall: {r:.4f}, F1: {f:.4f}, Support: {s}\")\n",
    "\n",
    "    p_macro, r_macro, f_macro, _ = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average='macro', zero_division=0\n",
    "    )\n",
    "    p_weighted, r_weighted, f_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true.ravel(), y_pred.ravel(), average='weighted', zero_division=0\n",
    "    )\n",
    "    print(f\"[{set_name} Macro]    Precision: {p_macro:.4f}, Recall: {r_macro:.4f}, F1: {f_macro:.4f}\")\n",
    "    print(f\"[{set_name} Weighted] Precision: {p_weighted:.4f}, Recall: {r_weighted:.4f}, F1: {f_weighted:.4f}\")\n",
    "\n",
    "# 8) 검증/테스트 세트 지표 출력\n",
    "y_val_true, y_val_pred = get_preds_targets(model, val_loader)\n",
    "print_scores(y_val_true, y_val_pred, set_name=\"Validation\")\n",
    "y_test_true, y_test_pred = get_preds_targets(model, test_loader)\n",
    "print_scores(y_test_true, y_test_pred, set_name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdaabb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.75      1.00      0.86         3\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.83      1.00      0.91         5\n",
      "           8       0.50      0.50      0.50         4\n",
      "           9       0.67      1.00      0.80         4\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      0.86      0.92         7\n",
      "          13       0.75      1.00      0.86         3\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         5\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      0.75      0.86         4\n",
      "          23       0.75      1.00      0.86         3\n",
      "          24       1.00      1.00      1.00         3\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      0.67      0.80         3\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       0.78      1.00      0.88         7\n",
      "          29       1.00      0.50      0.67         2\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       0.75      1.00      0.86         3\n",
      "          32       1.00      0.50      0.67         2\n",
      "          33       1.00      0.50      0.67         4\n",
      "          34       1.00      0.50      0.67         4\n",
      "          35       0.80      0.92      0.86        13\n",
      "          36       0.67      1.00      0.80         2\n",
      "          37       0.75      1.00      0.86         3\n",
      "          38       1.00      1.00      1.00         1\n",
      "          39       1.00      0.50      0.67         2\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       0.50      1.00      0.67         1\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         3\n",
      "          49       1.00      0.75      0.86         4\n",
      "          50       1.00      1.00      1.00         3\n",
      "          51       1.00      1.00      1.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      0.50      0.67         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       0.50      1.00      0.67         2\n",
      "          59       1.00      1.00      1.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.50      1.00      0.67         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.67      1.00      0.80         2\n",
      "          65       1.00      1.00      1.00         1\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         2\n",
      "          69       0.50      1.00      0.67         1\n",
      "          70       0.25      1.00      0.40         1\n",
      "          71       0.50      1.00      0.67         1\n",
      "          72       1.00      1.00      1.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.86       201\n",
      "   macro avg       0.76      0.79      0.75       201\n",
      "weighted avg       0.85      0.86      0.84       201\n",
      "\n",
      "Test set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       0.71      1.00      0.83         5\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.75      1.00      0.86         6\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      0.38      0.55         8\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      0.75      0.86         8\n",
      "           9       1.00      1.00      1.00         4\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00        11\n",
      "          12       1.00      1.00      1.00         9\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.50      1.00      0.67         1\n",
      "          16       0.89      0.89      0.89         9\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       0.50      1.00      0.67         1\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       0.67      0.33      0.44         6\n",
      "          27       1.00      0.50      0.67         2\n",
      "          28       0.83      1.00      0.91         5\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       0.67      1.00      0.80         6\n",
      "          33       0.50      1.00      0.67         1\n",
      "          34       1.00      0.50      0.67         2\n",
      "          35       0.67      1.00      0.80         4\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      0.33      0.50         3\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       0.75      1.00      0.86         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       0.33      1.00      0.50         1\n",
      "          47       1.00      1.00      1.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       1.00      1.00      1.00         4\n",
      "          51       1.00      0.67      0.80         3\n",
      "          52       0.75      1.00      0.86         3\n",
      "          54       1.00      1.00      1.00         7\n",
      "          56       0.25      1.00      0.40         2\n",
      "          57       1.00      0.50      0.67         2\n",
      "          58       1.00      0.50      0.67         2\n",
      "          59       0.50      1.00      0.67         1\n",
      "          60       1.00      0.50      0.67         2\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       1.00      0.67      0.80         3\n",
      "          64       0.50      1.00      0.67         2\n",
      "          65       1.00      0.75      0.86         4\n",
      "          66       0.00      0.00      0.00         1\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85       202\n",
      "   macro avg       0.80      0.80      0.77       202\n",
      "weighted avg       0.88      0.85      0.84       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) 데이터 준비\n",
    "X = cluster_df.iloc[:, 2:-2].to_numpy()\n",
    "y = cluster_df.iloc[:, -2].to_numpy()   # y가 1개 레이블일 때\n",
    "\n",
    "# 2) 데이터 분리\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 3) 나이브 베이즈 모델 적합\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4) 예측 및 평가\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Validation set performance:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n",
    "print(\"Test set performance:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
